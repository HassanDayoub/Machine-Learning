{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake News .ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HassanDayoub/Machine-Learning/blob/master/Fake_News_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfZLFiElTsYC",
        "colab_type": "text"
      },
      "source": [
        "#  **Fake News Detiction** (This Code belongs to [link text](https://data-flair.training/blogs/advanced-python-project-detecting-fake-news/) ) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avHnl_BsTgN2",
        "colab_type": "text"
      },
      "source": [
        "## What is Fake News?\n",
        "\n",
        "A type of yellow journalism, fake news encapsulates pieces of news that may be hoaxes and is generally spread through social media and other online media. This is often done to further or impose certain ideas and is often achieved with political agendas. Such news items may contain false and/or exaggerated claims, and may end up being viralized by algorithms, and users may end up in a filter bubble."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUo16FE-UcQh",
        "colab_type": "text"
      },
      "source": [
        "## What is a TfidfVectorizer?\n",
        "\n",
        "**TF (Term Frequency):** The number of times a word appears in a document is its Term Frequency. A higher value means a term appears more often than others, and so, the document is a good match when the term is part of the search terms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTtkB9feUr3y",
        "colab_type": "text"
      },
      "source": [
        "## What is a PassiveAggressiveClassifier?\n",
        "\n",
        "Passive Aggressive algorithms are online learning algorithms. Such an algorithm remains passive for a correct classification outcome, and turns aggressive in the event of a miscalculation, updating and adjusting. Unlike most other algorithms, it does not converge. Its purpose is to make updates that correct the loss, causing very little change in the norm of the weight vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D96ro12NU7gl",
        "colab_type": "text"
      },
      "source": [
        "## Detecting Fake News with Python – Objective\n",
        "\n",
        "To build a model to accurately classify a piece of news as REAL or FAKE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR0eD02WU-v6",
        "colab_type": "text"
      },
      "source": [
        "## Detecting Fake News with Python – About the Python Project\n",
        "\n",
        "This advanced python project of detecting fake news deals with fake and real news. Using sklearn, we build a TfidfVectorizer on our dataset. Then, we initialize a PassiveAggressive Classifier and fit the model. In the end, the accuracy score and the confusion matrix tell us how well our model fares.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87SJNi5cVDuT",
        "colab_type": "text"
      },
      "source": [
        "## The Dataset\n",
        "\n",
        "The dataset we’ll use for this python project- we’ll call it news.csv. This dataset has a shape of 7796×4. The first column identifies the news, the second and third are the title and text, and the fourth column has labels denoting whether the news is REAL or FAKE. The dataset takes up 29.2MB of space and you can download it here : [link text](https://drive.google.com/file/d/1er9NJTLUA3qnRuyhfzuN0XUsoIC4a-_q/view)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKOkBqAZdSAY",
        "colab_type": "code",
        "outputId": "f22aa9d6-c812-4cea-fed0-0ed69ad41268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMIqegtUdMvi",
        "colab_type": "code",
        "outputId": "7bc0bb7b-158d-4c32-fe9f-c8252aa9efba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip '/content/drive/My Drive/Colab Notebooks/Machine Learning Course AI Club/news.zip' -d '/content/drive/My Drive/Colab Notebooks/Machine Learning Course AI Club'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Colab Notebooks/Machine Learning Course AI Club/news.zip\n",
            "  inflating: /content/drive/My Drive/Colab Notebooks/Machine Learning Course AI Club/news.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNt1vljPVZMz",
        "colab_type": "text"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "You’ll need to install the following libraries with pip:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGIF6j57TBv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install numpy pandas sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoiVzGCwVuQE",
        "colab_type": "text"
      },
      "source": [
        "## Steps for detecting fake news with Python\n",
        "\n",
        "Follow the below steps for detecting fake news : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrdAPHK7V5Mx",
        "colab_type": "text"
      },
      "source": [
        "### 1. Make necessary imports:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMO-wbhhTSxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcyQFEZHWHpk",
        "colab_type": "text"
      },
      "source": [
        "### 2. Now, let’s **read** the data into a **DataFrame**, and get the **shape** of the data and the first 5 records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYGVp31vWMDJ",
        "colab_type": "code",
        "outputId": "e92efd26-443b-4d01-b4a2-dda87fc6998e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Read the data\n",
        "df=pd.read_csv('/content/news.csv')\n",
        "#Get shape and head\n",
        "df.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6335, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvbxswxxWVNi",
        "colab_type": "text"
      },
      "source": [
        "### 3. And get the labels from the DataFrame :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP9XdP5iWd_T",
        "colab_type": "code",
        "outputId": "be4060fc-aaf1-4b78-d100-6011930a3fd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#DataFlair - Get the labels\n",
        "labels=df.label\n",
        "labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    FAKE\n",
              "1    FAKE\n",
              "2    REAL\n",
              "3    FAKE\n",
              "4    REAL\n",
              "Name: label, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76aVQerHWnBZ",
        "colab_type": "text"
      },
      "source": [
        "### 4. Split the dataset into training and testing sets :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtMavkf5Worr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DataFlair - Split the dataset\n",
        "x_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.2, random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCXD-3teWsnA",
        "colab_type": "text"
      },
      "source": [
        "### 5. initialize a TfidfVectorizer :\n",
        "Let’s initialize a [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) with stop words from the English language and a maximum document frequency of 0.7 (terms with a higher document frequency will be discarded). Stop words are the most common words in a language that are to be filtered out before processing the natural language data. And a TfidfVectorizer turns a collection of raw documents into a matrix of TF-IDF features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PErBz0DPW3KB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DataFlair - Initialize a TfidfVectorizer\n",
        "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siVVNzDbX1oz",
        "colab_type": "text"
      },
      "source": [
        "Now, fit and transform the vectorizer on the train set, and transform the vectorizer on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5nYVre6X3a2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DataFlair - Fit and transform train set, transform test set\n",
        "tfidf_train=tfidf_vectorizer.fit_transform(x_train) \n",
        "tfidf_test=tfidf_vectorizer.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PoyjiHtYf_6",
        "colab_type": "text"
      },
      "source": [
        "### 6. initialize a PassiveAggressiveClassifier:\n",
        "\n",
        "Next, we’ll initialize a [PassiveAggressiveClassifier](https://en.wikipedia.org/wiki/Online_machine_learning). This is. We’ll fit this on tfidf_train and y_train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK81FW4jYji_",
        "colab_type": "code",
        "outputId": "39402cfe-07b7-4984-ec29-33fd1e6cf5d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#DataFlair - Initialize a PassiveAggressiveClassifier\n",
        "pac=PassiveAggressiveClassifier(max_iter=50)\n",
        "pac.fit(tfidf_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
              "                            early_stopping=False, fit_intercept=True,\n",
              "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
              "                            n_jobs=None, random_state=None, shuffle=True,\n",
              "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "                            warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nW5eHSkY2HK",
        "colab_type": "text"
      },
      "source": [
        "Then, we’ll predict on the test set from the TfidfVectorizer and calculate the accuracy with accuracy_score() from sklearn.metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR4UH2CzYzHd",
        "colab_type": "code",
        "outputId": "3f58f758-4d6d-46fb-a0b9-190e863af7e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#DataFlair - Predict on the test set and calculate accuracy\n",
        "y_pred=pac.predict(tfidf_test)\n",
        "score=accuracy_score(y_test,y_pred)\n",
        "print(f'Accuracy: {round(score*100,2)}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 92.74%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG43NwpTZF_h",
        "colab_type": "text"
      },
      "source": [
        "### 7. Confusion matrix : \n",
        "\n",
        " Finally, let’s print out a confusion matrix to gain insight into the number of false and true negatives and positives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbwjOP26ZLck",
        "colab_type": "code",
        "outputId": "0c26d74c-a7ec-4194-d951-00befe5fe8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#DataFlair - Build confusion matrix\n",
        "confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[587,  51],\n",
              "       [ 41, 588]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtIfFdwTZSGk",
        "colab_type": "text"
      },
      "source": [
        "So with this model, we have 589 true positives, 587 true negatives, 42 false positives, and 49 false negatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMpslZycZSoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}